{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cf76dd8-34a2-4276-85c1-2b6ddf058edf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "df_silver = spark.table(\"cvee.jobs_silver\")\n",
    "df_silver=df_silver.drop(\"vector_text_input\")\n",
    "json_cols = [\"lieuTravail\", \"entreprise\", \"contact\", \"agence\",\n",
    "             \"origineOffre\", \"contexteTravail\",\n",
    "             \"salaire\", \"competences\", \"formations\", \"langues\",\n",
    "             \"permis\", \"qualitesProfessionnelles\"]\n",
    "for col in json_cols:\n",
    "    if col in df_silver.columns:\n",
    "        df_silver = df_silver.withColumn(col, F.to_json(F.col(col)))\n",
    "\n",
    "max_ingestion_date = df_silver.agg(F.max(\"ingestion_date\")).collect()[0][0]\n",
    "df_silver = df_silver.filter(F.col(\"ingestion_date\") == max_ingestion_date)\n",
    "\n",
    "\n",
    "\n",
    "#Export silver table\n",
    "df_silver.write.mode(\"overwrite\").parquet(\"s3a://cvee-bucket-eu-north-1/jobs_silver\")\n",
    "\n",
    "\n",
    "#display\n",
    "num_rows = df_silver.count()\n",
    "column_names = df_silver.columns\n",
    "print(f\"Number of lines sent : {num_rows}\")\n",
    "print(f\"Number of columns : {len(column_names)}\")\n",
    "print(f\"Columns : {column_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c5b179c-5f0a-4aa8-93db-eb70fac63a8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_gold = spark.table(\"cvee.jobs_gold\")\n",
    "df_gold = df_gold.withColumn(\"embedding\", F.to_json(F.col(\"embedding\")))\n",
    "df_gold = df_gold.filter(F.col(\"ingestion_date\") == max_ingestion_date)\n",
    "\n",
    "#Export gold table\n",
    "df_gold.write.mode(\"overwrite\").parquet(\"s3a://cvee-bucket-eu-north-1/jobs_gold\")\n",
    "\n",
    "#display\n",
    "num_rows = df_gold.count()\n",
    "column_names = df_gold.columns\n",
    "print(f\"Number of lines sent : {num_rows}\")\n",
    "print(f\"Number of columns : {len(column_names)}\")\n",
    "print(f\"Columns : {column_names}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "jobs_export",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
