{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61c7b2fe-b6e3-447d-b2d9-51ccf4215ac2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install sentence-transformers==2.2.2 torch --quiet\n",
    "%pip install \"huggingface_hub<=0.24.0\" \"sentence-transformers>=2.6.1\"\n",
    "\n",
    "%restart_python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c854976a-c8d7-416e-bbda-89cdf29c60c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, FloatType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import pandas_udf, col, substring\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from delta.tables import DeltaTable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c4cdbfa-2c90-4d08-a6a9-95810fd2c58d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Importing bge-small-en model\n",
    "\n",
    "MODEL_NAME = \"BAAI/bge-small-en\"\n",
    "print(\"Model loading:\", MODEL_NAME)\n",
    "model = SentenceTransformer(MODEL_NAME, trust_remote_code=True)\n",
    "EMBED_DIM = len(model.encode(\"test\").tolist())\n",
    "\n",
    "@pandas_udf(ArrayType(FloatType()))\n",
    "def embedding_pandas_udf(texts: pd.Series) -> pd.Series:\n",
    "    texts_filled = texts.fillna(\"\")\n",
    "    embeddings = model.encode(texts_filled.tolist(), show_progress_bar=True, convert_to_numpy=True)\n",
    "    return pd.Series([emb.astype(float).tolist() for emb in embeddings])\n",
    "\n",
    "\n",
    "silver_table = \"cvee.jobs_silver\"\n",
    "gold_table = \"cvee.jobs_gold\"\n",
    "\n",
    "\n",
    "silver_df = spark.table(silver_table).select([\"job_id\", \"vector_text_input\", \"ingestion_date\"])\n",
    "gold_df = spark.table(gold_table).select(\"job_id\")\n",
    "\n",
    "\n",
    "df_reduced=silver_df.join(gold_df, on=\"job_id\", how=\"left_anti\")\n",
    "df_prepared = df_reduced.withColumn(\"vector_text_input\", F.when(col(\"vector_text_input\").isNull(), F.lit(\"\")).otherwise(col(\"vector_text_input\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6128f442-f36e-4707-8cd0-0c9091c335f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Embedding\n",
    "\n",
    "NUM_PARTITIONS = 100\n",
    "df_repart = df_prepared.repartition(NUM_PARTITIONS)\n",
    "print(\"Partitions:\", NUM_PARTITIONS)\n",
    "\n",
    "gold_df = df_repart.withColumn(\"embedding\", embedding_pandas_udf(F.col(\"vector_text_input\")))\n",
    "golf_df=gold_df.select(\"job_id\", \"embedding\", 'ingestion_date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "daa6d694-5683-4a0c-8321-6b3130146d2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DELTA_TABLE_PATH=\"cvee.jobs_gold\"\n",
    "print(f\"Merging into Delta table {DELTA_TABLE_PATH}\")\n",
    "\n",
    "try:\n",
    "    delta_table = DeltaTable.forName(spark, DELTA_TABLE_PATH)\n",
    "    old_count = delta_table.toDF().count()\n",
    "    delta_table.alias(\"target\").merge(\n",
    "        golf_df.alias(\"source\"),\n",
    "        \"target.job_id = source.job_id\"\n",
    "    ).whenNotMatchedInsertAll().execute()\n",
    "\n",
    "    new_count = delta_table.toDF().count()\n",
    "    print(f\"Number of rows added: {new_count - old_count} / {golf_df.count()} read\")\n",
    "except:\n",
    "    golf_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(DELTA_TABLE_PATH)\n",
    "    print(f\"Table created with {golf_df.count()} rows\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7375049592732470,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "jobs_embeddings_gold",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
